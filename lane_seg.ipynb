{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2936, Val: 327, Test: 363\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 367\u001b[0m\n\u001b[1;32m    365\u001b[0m prep\u001b[38;5;241m.\u001b[39mmake_dir()\n\u001b[1;32m    366\u001b[0m prep\u001b[38;5;241m.\u001b[39msplit_dataset(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, val_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m--> 367\u001b[0m train_X, train_Y, val_X, val_Y, test_X, test_Y \u001b[38;5;241m=\u001b[39m \u001b[43mprep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    369\u001b[0m train_X \u001b[38;5;241m=\u001b[39m train_X\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    370\u001b[0m val_X   \u001b[38;5;241m=\u001b[39m val_X\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 77\u001b[0m, in \u001b[0;36mPreProcessing.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m     train_X, train_Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_lane_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_img_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mask_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     val_X, val_Y     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_lane_mask(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_img_folder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_mask_folder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_images, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_masks)\n\u001b[1;32m     79\u001b[0m     test_X, test_Y   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_lane_mask(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_img_folder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_mask_folder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_images, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_masks)\n",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m, in \u001b[0;36mPreProcessing.generate_lane_mask\u001b[0;34m(self, img_folder, mask_folder, img_files, mask_files)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(img_path) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(mask_path):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(mask_path,cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score\n",
    "from tensorflow.keras import layers, Model, Input,applications\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, BatchNormalization, Activation,Add\n",
    "from tensorflow.keras.applications import MobileNet as KerasMobileNet\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "\n",
    "class PreProcessing:\n",
    "    def __init__(self,base_path = \"processed\",img_size=(224,224)):\n",
    "        self.base_path = base_path\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.image_folder = os.path.join(base_path,\"images\") \n",
    "        self.mask_folder = os.path.join(base_path,\"masks\")\n",
    "        self.train_img_folder = os.path.join(base_path,\"train/images\")\n",
    "        self.train_mask_folder = os.path.join(base_path,\"train/masks\")\n",
    "        self.val_img_folder = os.path.join(base_path,\"val/images\")\n",
    "        self.val_mask_folder = os.path.join(base_path,\"val/masks\")\n",
    "        self.test_img_folder = os.path.join(base_path,\"test/images\")\n",
    "        self.test_mask_folder = os.path.join(base_path,\"test/masks\")\n",
    "\n",
    "    def make_dir(self):\n",
    "        folders = [self.image_folder,self.mask_folder ,self.train_img_folder,self.train_mask_folder,self.val_img_folder,self.val_mask_folder ,self.test_img_folder,self.test_mask_folder ]\n",
    "        for folder in folders:\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "    \n",
    "    def split_dataset(self,test_size=0.1,val_size=0.1):\n",
    "        images = sorted([f for f in os.listdir(self.image_folder) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "        masks  = sorted([f for f in os.listdir(self.mask_folder) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "        train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=test_size, random_state=42)\n",
    "        train_images, val_images, train_masks, val_masks = train_test_split(train_images, train_masks, test_size=val_size, random_state=42)\n",
    "\n",
    "        self.train_images, self.val_images, self.test_images = train_images, val_images, test_images\n",
    "        self.train_masks, self.val_masks, self.test_masks = train_masks, val_masks, test_masks\n",
    "\n",
    "        print(f\"Train: {len(train_images)}, Val: {len(val_images)}, Test: {len(test_images)}\")\n",
    "\n",
    "    def generate_lane_mask(self,img_folder,mask_folder,img_files,mask_files):\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_file,mask_file in zip(img_files,mask_files):\n",
    "            img_path = os.path.join(img_folder,img_file)\n",
    "            mask_path = os.path.join(mask_folder,mask_file)\n",
    "            if not os.path.exists(img_path) or not os.path.exists(mask_path):\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            mask = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None or mask is None:\n",
    "                continue\n",
    "\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img,self.img_size) / 255.0\n",
    "            mask = cv2.resize(mask,self.img_size) / 255.0\n",
    "            mask = np.expand_dims(mask, -1)\n",
    "\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "        return np.array(images, np.float32), np.array(masks, np.float32)\n",
    "    \n",
    "    def load_data(self):\n",
    "        train_X, train_Y = self.generate_lane_mask(self.train_img_folder, self.train_mask_folder, self.train_images, self.train_masks)\n",
    "        val_X, val_Y     = self.generate_lane_mask(self.val_img_folder, self.val_mask_folder, self.val_images, self.val_masks)\n",
    "        test_X, test_Y   = self.generate_lane_mask(self.test_img_folder, self.test_mask_folder, self.test_images, self.test_masks)\n",
    "        print(\"Data loaded:\", train_X.shape, val_X.shape, test_X.shape)\n",
    "        return train_X, train_Y, val_X, val_Y, test_X, test_Y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PathConnectivity:\n",
    "    def __init__(self,connectivity=8):\n",
    "        self.connectivity = connectivity\n",
    "        self.kernel = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    def dilate_mask(self,mask):\n",
    "        return cv2.dilate(mask,self.kernel,iterations=1)\n",
    "    \n",
    "    def iou(self,mask_pred,mask_gt):\n",
    "        mask_pred_dilated = self.dilate_mask(mask_pred.astype(np.uint8))\n",
    "        mask_gt_dilated = self.dilate_mask(mask_gt.astype(np.uint8))\n",
    "\n",
    "        intersection = np.logical_and(mask_pred_dilated, mask_gt_dilated).sum()\n",
    "        union = np.logical_or(mask_pred_dilated, mask_gt_dilated).sum()\n",
    "        if union == 0:\n",
    "            return 1.0 \n",
    "        return intersection / union\n",
    "\n",
    "\n",
    "class Visulation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def show_image_mask(self, image, mask_gt, mask_pred=None, iou_score=None):\n",
    "        \"\"\"\n",
    "        GÃ¶rselleÅŸtirme fonksiyonu\n",
    "        image      : RGB image (H,W,3)\n",
    "        mask_gt    : Ground truth mask (H,W)\n",
    "        mask_pred  : Tahmin maskesi (H,W) - optional\n",
    "        iou_score  : IoU deÄŸeri - optional\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12,4))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(mask_gt[:,:,0] if mask_gt.ndim==3 else mask_gt, cmap='gray')\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        if mask_pred is not None:\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.imshow(mask_pred[:,:,0] if mask_pred.ndim==3 else mask_pred, cmap='gray')\n",
    "            title = \"Prediction\"\n",
    "            if iou_score is not None:\n",
    "                title += f\" | IoU: {iou_score:.4f}\"\n",
    "            plt.title(title)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def overlay_masks(self, image, mask_gt, mask_pred, alpha=0.5):\n",
    "        overlay = image.copy()\n",
    "        mask_gt_colored = np.zeros_like(image)\n",
    "        mask_gt_colored[:,:,0] = mask_gt[:,:,0]*255  \n",
    "        mask_pred_colored = np.zeros_like(image)\n",
    "        mask_pred_colored[:,:,1] = mask_pred[:,:,0]*255  \n",
    "\n",
    "        combined = cv2.addWeighted(overlay,1.0,mask_gt_colored,alpha,0)\n",
    "        combined = cv2.addWeighted(combined,1.0,mask_pred_colored,alpha,0)\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(combined.astype(np.uint8))\n",
    "        plt.title(\"Overlay: Red=GT, Green=Prediction\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "#MODELS\n",
    "##----------------------------------------------------------------------------------------------------------------------------------##\n",
    "class VGG19Seg(Model):\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        super(VGG19Seg, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1_1 = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv1_2 = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.pool1 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "        self.conv2_1 = layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv2_2 = layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.pool2 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "        self.conv3_1 = layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv3_2 = layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv3_3 = layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv3_4 = layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.pool3 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "        self.conv4_1 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv4_2 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv4_3 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv4_4 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.pool4 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "        self.conv5_1 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv5_2 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv5_3 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.conv5_4 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.pool5 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = layers.UpSampling2D((2,2))\n",
    "        self.dec1 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up2 = layers.UpSampling2D((2,2))\n",
    "        self.dec2 = layers.Conv2D(512, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up3 = layers.UpSampling2D((2,2))\n",
    "        self.dec3 = layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up4 = layers.UpSampling2D((2,2))\n",
    "        self.dec4 = layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up5 = layers.UpSampling2D((2,2))\n",
    "        self.dec5 = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")\n",
    "\n",
    "        self.final = layers.Conv2D(1, (1,1), activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Encoder\n",
    "        x1 = self.conv1_1(inputs)\n",
    "        x1 = self.conv1_2(x1)\n",
    "        p1 = self.pool1(x1)\n",
    "\n",
    "        x2 = self.conv2_1(p1)\n",
    "        x2 = self.conv2_2(x2)\n",
    "        p2 = self.pool2(x2)\n",
    "\n",
    "        x3 = self.conv3_1(p2)\n",
    "        x3 = self.conv3_2(x3)\n",
    "        x3 = self.conv3_3(x3)\n",
    "        x3 = self.conv3_4(x3)\n",
    "        p3 = self.pool3(x3)\n",
    "\n",
    "        x4 = self.conv4_1(p3)\n",
    "        x4 = self.conv4_2(x4)\n",
    "        x4 = self.conv4_3(x4)\n",
    "        x4 = self.conv4_4(x4)\n",
    "        p4 = self.pool4(x4)\n",
    "\n",
    "        x5 = self.conv5_1(p4)\n",
    "        x5 = self.conv5_2(x5)\n",
    "        x5 = self.conv5_3(x5)\n",
    "        x5 = self.conv5_4(x5)\n",
    "        p5 = self.pool5(x5)\n",
    "\n",
    "        # Decoder with skip conections(Most important part)\n",
    "        u1 = self.up1(p5)\n",
    "        u1 = layers.Concatenate()([u1, x5])\n",
    "        u1 = self.dec1(u1)\n",
    "\n",
    "        u2 = self.up2(u1)\n",
    "        u2 = layers.Concatenate()([u2, x4])\n",
    "        u2 = self.dec2(u2)\n",
    "\n",
    "        u3 = self.up3(u2)\n",
    "        u3 = layers.Concatenate()([u3, x3])\n",
    "        u3 = self.dec3(u3)\n",
    "\n",
    "        u4 = self.up4(u3)\n",
    "        u4 = layers.Concatenate()([u4, x2])\n",
    "        u4 = self.dec4(u4)\n",
    "\n",
    "        u5 = self.up5(u4)\n",
    "        u5 = layers.Concatenate()([u5, x1])\n",
    "        u5 = self.dec5(u5)\n",
    "\n",
    "        return self.final(u5)\n",
    "\n",
    "class ResNet50Seg(Model):\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        super(ResNet50Seg, self).__init__()\n",
    "        # Pretrained ResNet50 backbone\n",
    "        self.backbone = tf.keras.applications.ResNet50(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "        self.backbone.trainable = True  # If you want, you can set it to False and train only the decoder\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = layers.UpSampling2D((2,2)); self.dec1 = layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up2 = layers.UpSampling2D((2,2)); self.dec2 = layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up3 = layers.UpSampling2D((2,2)); self.dec3 = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up4 = layers.UpSampling2D((2,2)); self.dec4 = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up5 = layers.UpSampling2D((2,2)); self.dec5 = layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.final = layers.Conv2D(1, (1,1), activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.backbone(inputs)\n",
    "        x = self.up1(x); x = self.dec1(x)\n",
    "        x = self.up2(x); x = self.dec2(x)\n",
    "        x = self.up3(x); x = self.dec3(x)\n",
    "        x = self.up4(x); x = self.dec4(x)\n",
    "        x = self.up5(x); x = self.dec5(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "\n",
    "class MobileNetSeg(Model):\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        super(MobileNetSeg, self).__init__()\n",
    "        self.backbone = MobileNet(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "        self.up1 = UpSampling2D((2,2))\n",
    "        self.dec1 = Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up2 = UpSampling2D((2,2))\n",
    "        self.dec2 = Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up3 = UpSampling2D((2,2))\n",
    "        self.dec3 = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up4 = UpSampling2D((2,2))\n",
    "        self.dec4 = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up5 = UpSampling2D((2,2))\n",
    "        self.dec5 = Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.final = Conv2D(1, (1,1), activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.backbone(inputs)\n",
    "        x = self.up1(x); x = self.dec1(x)\n",
    "        x = self.up2(x); x = self.dec2(x)\n",
    "        x = self.up3(x); x = self.dec3(x)\n",
    "        x = self.up4(x); x = self.dec4(x)\n",
    "        x = self.up5(x); x = self.dec5(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "class EfficientNetSeg(Model):\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        super(EfficientNetSeg, self).__init__()\n",
    "        self.backbone = tf.keras.applications.EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = UpSampling2D((2,2)); self.dec1 = Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up2 = UpSampling2D((2,2)); self.dec2 = Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up3 = UpSampling2D((2,2)); self.dec3 = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up4 = UpSampling2D((2,2)); self.dec4 = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up5 = UpSampling2D((2,2)); self.dec5 = Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.final = Conv2D(1, (1,1), activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.backbone(inputs)\n",
    "        x = self.up1(x); x = self.dec1(x)\n",
    "        x = self.up2(x); x = self.dec2(x)\n",
    "        x = self.up3(x); x = self.dec3(x)\n",
    "        x = self.up4(x); x = self.dec4(x)\n",
    "        x = self.up5(x); x = self.dec5(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "class DenseNetSeg(Model):\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        super(DenseNetSeg, self).__init__()\n",
    "        self.backbone = tf.keras.applications.DenseNet121(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = UpSampling2D((2,2)); self.dec1 = Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up2 = UpSampling2D((2,2)); self.dec2 = Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up3 = UpSampling2D((2,2)); self.dec3 = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up4 = UpSampling2D((2,2)); self.dec4 = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.up5 = UpSampling2D((2,2)); self.dec5 = Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")\n",
    "        self.final = Conv2D(1, (1,1), activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.backbone(inputs)\n",
    "        x = self.up1(x); x = self.dec1(x)\n",
    "        x = self.up2(x); x = self.dec2(x)\n",
    "        x = self.up3(x); x = self.dec3(x)\n",
    "        x = self.up4(x); x = self.dec4(x)\n",
    "        x = self.up5(x); x = self.dec5(x)\n",
    "        return self.final(x)\n",
    "\n",
    "class Loss:\n",
    "    @staticmethod\n",
    "    def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "        y_true_f = tf.reshape(y_true, [-1])\n",
    "        y_pred_f = tf.reshape(y_pred, [-1])\n",
    "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "        return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "    @staticmethod\n",
    "    def weighted_bce_dice_loss(y_true, y_pred, weight=5):\n",
    "        bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "        dice = Loss.dice_loss(y_true, y_pred)\n",
    "        return bce + weight * dice\n",
    "\n",
    "prep = PreProcessing(base_path=\"processed\", img_size=(224,224))\n",
    "prep.make_dir()\n",
    "prep.split_dataset(test_size=0.1, val_size=0.1)\n",
    "train_X, train_Y, val_X, val_Y, test_X, test_Y = prep.load_data()  \n",
    "\n",
    "train_X = train_X.astype(\"float32\")\n",
    "val_X   = val_X.astype(\"float32\")\n",
    "test_X  = test_X.astype(\"float32\")\n",
    "train_Y = train_Y.astype(\"float32\")\n",
    "val_Y   = val_Y.astype(\"float32\")\n",
    "test_Y  = test_Y.astype(\"float32\")\n",
    "\n",
    "if train_Y.max() > 1.0:\n",
    "    train_Y /= 255.0\n",
    "    val_Y   /= 255.0\n",
    "    test_Y  /= 255.0\n",
    "\n",
    "\n",
    "models_subclass = {\n",
    "    \"vgg19seg_model\": VGG19Seg,\n",
    "    \"resnet50_model\": ResNet50Seg,\n",
    "    \"mobilenet_model\": MobileNetSeg,\n",
    "    \"efficientnet_model\": EfficientNetSeg,\n",
    "    \"densenet_model\": DenseNetSeg\n",
    "}\n",
    "\n",
    "def train_and_save_model(model_class, save_name, train_X, train_Y, val_X, val_Y):\n",
    "    print(f\"\\Training {save_name}...\")\n",
    "\n",
    "    model = model_class(input_shape=(224,224,3))\n",
    "    inputs = tf.keras.Input(shape=(224,224,3))\n",
    "    _ = model(inputs)  # Build and weight init\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(1e-4),\n",
    "        loss=Loss.weighted_bce_dice_loss,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_X, train_Y,\n",
    "        validation_data=(val_X, val_Y),\n",
    "        batch_size=4,\n",
    "        epochs=10,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.save(save_name, save_format=\"tf\")\n",
    "    print(f\"{save_name} baÅŸarÄ±yla kaydedildi!\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Training snd save for all models\n",
    "for save_name, cls in models_subclass.items():\n",
    "    try:\n",
    "        model, history = train_and_save_model(cls, save_name, train_X, train_Y, val_X, val_Y)\n",
    "    except Exception as e:\n",
    "        print(f\"{save_name} there is a problem at training:\\n{e}\")\n",
    "\n",
    "\n",
    "print(\"Test shape:\", test_X.shape, test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a9d776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: densenet_model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg19seg_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdensenet_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m preds_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtrain_X\u001b[49m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m preds_test_bin \u001b[38;5;241m=\u001b[39m (preds_test \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m      7\u001b[0m pc \u001b[38;5;241m=\u001b[39m PathConnectivity(connectivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"vgg19seg_model\", compile=False)\n",
    "print(\"Model loaded:\", \"densenet_model\")\n",
    "\n",
    "preds_test = model.predict(train_X, verbose=1)\n",
    "preds_test_bin = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "pc = PathConnectivity(connectivity=8)\n",
    "\n",
    "ious = []\n",
    "for gt, pred in zip(train_Y, preds_test_bin):\n",
    "    iou_score = pc.iou(pred, gt)\n",
    "    ious.append(iou_score)\n",
    "\n",
    "mean_iou = np.mean(ious)\n",
    "print(f\"\\nðŸ“Š Mean IoU (PathConnectivity, dilate ile): {mean_iou:.4f}\")\n",
    "\n",
    "vis = Visulation()\n",
    "n_samples = 5\n",
    "indices = np.random.choice(len(train_X), n_samples, replace=False)\n",
    "\n",
    "for idx in indices:\n",
    "    vis.show_image_mask(\n",
    "        train_X[idx],\n",
    "        train_Y[idx],\n",
    "        preds_test_bin[idx],\n",
    "        iou_score=pc.iou(preds_test_bin[idx], train_Y[idx])\n",
    "    )\n",
    "\n",
    "    vis.overlay_masks(\n",
    "        train_X[idx],\n",
    "        train_Y[idx],\n",
    "        preds_test_bin[idx]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESNET50 Segmentation\n",
    "#I wrote the open version of resnet50 but I couldn't use it because it was running very slow\n",
    "#If you want you can paste this resnet50 code above\n",
    "class RESNET50(Model):\n",
    "    def __init__(self, input_shape=(224,224,3)):\n",
    "        super(RESNET50, self).__init__()\n",
    "        self.conv1 = Conv2D(64, (7,7), strides=(2,2), padding=\"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.relu1 = Activation(\"relu\")\n",
    "        self.pool1 = MaxPooling2D((3,3), strides=(2,2), padding=\"same\")\n",
    "\n",
    "        # Conv and Identity block 64\n",
    "        self.id1_conv1 = Conv2D(64, (3,3), padding=\"same\")\n",
    "        self.id1_bn1 = BatchNormalization()\n",
    "        self.id1_conv2 = Conv2D(64, (3,3), padding=\"same\")\n",
    "        self.id1_bn2 = BatchNormalization()\n",
    "        \n",
    "        self.id2_conv1 = Conv2D(64, (3,3), padding=\"same\")\n",
    "        self.id2_bn1 = BatchNormalization()\n",
    "        self.id2_conv2 = Conv2D(64, (3,3), padding=\"same\")\n",
    "        self.id2_bn2 = BatchNormalization()\n",
    "        \n",
    "        # Conv block 128\n",
    "        self.cb128_shortcut = Conv2D(128, (1,1), strides=(2,2), padding=\"same\")\n",
    "        self.cb128_bn_shortcut = BatchNormalization()\n",
    "        self.cb128_conv1 = Conv2D(128, (3,3), strides=(2,2), padding=\"same\")\n",
    "        self.cb128_bn1 = BatchNormalization()\n",
    "        self.cb128_conv2 = Conv2D(128, (3,3), padding=\"same\")\n",
    "        self.cb128_bn2 = BatchNormalization()\n",
    "        \n",
    "        # Identity block 128\n",
    "        self.id3_conv1 = Conv2D(128, (3,3), padding=\"same\")\n",
    "        self.id3_bn1 = BatchNormalization()\n",
    "        self.id3_conv2 = Conv2D(128, (3,3), padding=\"same\")\n",
    "        self.id3_bn2 = BatchNormalization()\n",
    "        \n",
    "        # Conv block 256\n",
    "        self.cb256_shortcut = Conv2D(256, (1,1), strides=(2,2), padding=\"same\")\n",
    "        self.cb256_bn_shortcut = BatchNormalization()\n",
    "        self.cb256_conv1 = Conv2D(256, (3,3), strides=(2,2), padding=\"same\")\n",
    "        self.cb256_bn1 = BatchNormalization()\n",
    "        self.cb256_conv2 = Conv2D(256, (3,3), padding=\"same\")\n",
    "        self.cb256_bn2 = BatchNormalization()\n",
    "        \n",
    "        # Identity block 256\n",
    "        self.id4_conv1 = Conv2D(256, (3,3), padding=\"same\")\n",
    "        self.id4_bn1 = BatchNormalization()\n",
    "        self.id4_conv2 = Conv2D(256, (3,3), padding=\"same\")\n",
    "        self.id4_bn2 = BatchNormalization()\n",
    "        \n",
    "        # Conv block 512\n",
    "        self.cb512_shortcut = Conv2D(512, (1,1), strides=(2,2), padding=\"same\")\n",
    "        self.cb512_bn_shortcut = BatchNormalization()\n",
    "        self.cb512_conv1 = Conv2D(512, (3,3), strides=(2,2), padding=\"same\")\n",
    "        self.cb512_bn1 = BatchNormalization()\n",
    "        self.cb512_conv2 = Conv2D(512, (3,3), padding=\"same\")\n",
    "        self.cb512_bn2 = BatchNormalization()\n",
    "        \n",
    "        # Identity block 512\n",
    "        self.id5_conv1 = Conv2D(512, (3,3), padding=\"same\")\n",
    "        self.id5_bn1 = BatchNormalization()\n",
    "        self.id5_conv2 = Conv2D(512, (3,3), padding=\"same\")\n",
    "        self.id5_bn2 = BatchNormalization()\n",
    "\n",
    "        # Decoder layer\n",
    "        self.dec1_conv1 = Conv2D(256, (3,3), padding=\"same\")\n",
    "        self.dec1_bn1 = BatchNormalization()\n",
    "        self.dec1_conv2 = Conv2D(256, (3,3), padding=\"same\")\n",
    "        self.dec1_bn2 = BatchNormalization()\n",
    "        \n",
    "        self.dec2_conv1 = Conv2D(128, (3,3), padding=\"same\")\n",
    "        self.dec2_bn1 = BatchNormalization()\n",
    "        self.dec2_conv2 = Conv2D(128, (3,3), padding=\"same\")\n",
    "        self.dec2_bn2 = BatchNormalization()\n",
    "        \n",
    "        self.dec3_conv1 = Conv2D(64, (3,3), padding=\"same\")\n",
    "        self.dec3_bn1 = BatchNormalization()\n",
    "        self.dec3_conv2 = Conv2D(64, (3,3), padding=\"same\")\n",
    "        self.dec3_bn2 = BatchNormalization()\n",
    "        \n",
    "        self.dec4_conv1 = Conv2D(32, (3,3), padding=\"same\")\n",
    "        self.dec4_bn1 = BatchNormalization()\n",
    "        self.dec4_conv2 = Conv2D(32, (3,3), padding=\"same\")\n",
    "        self.dec4_bn2 = BatchNormalization()\n",
    "        \n",
    "        self.dec5_conv1 = Conv2D(16, (3,3), padding=\"same\")\n",
    "        self.dec5_bn1 = BatchNormalization()\n",
    "        self.dec5_conv2 = Conv2D(16, (3,3), padding=\"same\")\n",
    "        self.dec5_bn2 = BatchNormalization()\n",
    "\n",
    "        # UpSampling and final\n",
    "        self.up1 = UpSampling2D((2,2))\n",
    "        self.up2 = UpSampling2D((2,2))\n",
    "        self.up3 = UpSampling2D((2,2))\n",
    "        self.up4 = UpSampling2D((2,2))\n",
    "        self.up5 = UpSampling2D((2,2))\n",
    "        self.final_conv = Conv2D(1, (1,1), activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Initial conv\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Identity block 1 (64)\n",
    "        shortcut = x\n",
    "        x = self.id1_conv1(x)\n",
    "        x = self.id1_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.id1_conv2(x)\n",
    "        x = self.id1_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Identity block 2 (64)\n",
    "        shortcut = x\n",
    "        x = self.id2_conv1(x)\n",
    "        x = self.id2_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.id2_conv2(x)\n",
    "        x = self.id2_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Conv block 128\n",
    "        shortcut = self.cb128_shortcut(x)\n",
    "        shortcut = self.cb128_bn_shortcut(shortcut)\n",
    "        x = self.cb128_conv1(x)\n",
    "        x = self.cb128_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.cb128_conv2(x)\n",
    "        x = self.cb128_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Identity block 3 (128)\n",
    "        shortcut = x\n",
    "        x = self.id3_conv1(x)\n",
    "        x = self.id3_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.id3_conv2(x)\n",
    "        x = self.id3_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Conv block 256\n",
    "        shortcut = self.cb256_shortcut(x)\n",
    "        shortcut = self.cb256_bn_shortcut(shortcut)\n",
    "        x = self.cb256_conv1(x)\n",
    "        x = self.cb256_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.cb256_conv2(x)\n",
    "        x = self.cb256_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Identity block 4 (256)\n",
    "        shortcut = x\n",
    "        x = self.id4_conv1(x)\n",
    "        x = self.id4_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.id4_conv2(x)\n",
    "        x = self.id4_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Conv block 512\n",
    "        shortcut = self.cb512_shortcut(x)\n",
    "        shortcut = self.cb512_bn_shortcut(shortcut)\n",
    "        x = self.cb512_conv1(x)\n",
    "        x = self.cb512_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.cb512_conv2(x)\n",
    "        x = self.cb512_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        # Identity block 5 (512)\n",
    "        shortcut = x\n",
    "        x = self.id5_conv1(x)\n",
    "        x = self.id5_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.id5_conv2(x)\n",
    "        x = self.id5_bn2(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x)\n",
    "        x = self.dec1_conv1(x)\n",
    "        x = self.dec1_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.dec1_conv2(x)\n",
    "        x = self.dec1_bn2(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = self.up2(x)\n",
    "        x = self.dec2_conv1(x)\n",
    "        x = self.dec2_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.dec2_conv2(x)\n",
    "        x = self.dec2_bn2(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = self.up3(x)\n",
    "        x = self.dec3_conv1(x)\n",
    "        x = self.dec3_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.dec3_conv2(x)\n",
    "        x = self.dec3_bn2(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = self.up4(x)\n",
    "        x = self.dec4_conv1(x)\n",
    "        x = self.dec4_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.dec4_conv2(x)\n",
    "        x = self.dec4_bn2(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = self.up5(x)\n",
    "        x = self.dec5_conv1(x)\n",
    "        x = self.dec5_bn1(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = self.dec5_conv2(x)\n",
    "        x = self.dec5_bn2(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72158651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2c732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed411ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04505b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b98fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabcf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d69c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
